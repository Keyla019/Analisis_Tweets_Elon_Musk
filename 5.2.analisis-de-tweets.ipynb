{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41154291-76ee-416d-8106-9d47c52b272f",
   "metadata": {
    "id": "41154291-76ee-416d-8106-9d47c52b272f"
   },
   "source": [
    "# AnÃ¡lisis de tweets\n",
    "\n",
    "*Elon Musk*\n",
    "\n",
    "Se facilita una lista de `dict` con datos reales de ventas con las siguientes keys:\n",
    "\n",
    "* 'Unnamed: 0'\n",
    "* 'id'\n",
    "* 'conversation_id'\n",
    "* 'created_at'\n",
    "* 'date'\n",
    "* 'timezone'\n",
    "* 'place'\n",
    "* 'tweet'\n",
    "* 'language'\n",
    "* 'hashtags'\n",
    "* 'cashtags'\n",
    "* 'user_id'\n",
    "* 'user_id_str'\n",
    "* 'username'\n",
    "* 'name'\n",
    "* 'day'\n",
    "* 'hour'\n",
    "* 'link'\n",
    "* 'urls'\n",
    "* 'photos'\n",
    "* 'video'\n",
    "* 'thumbnail'\n",
    "* 'retweet'\n",
    "* 'nlikes'\n",
    "* 'nreplies'\n",
    "* 'nretweets'\n",
    "* 'quote_url'\n",
    "* 'search'\n",
    "* 'near'\n",
    "* 'geo'\n",
    "* 'source'\n",
    "* 'user_rt_id'\n",
    "* 'user_rt'\n",
    "* 'retweet_id'\n",
    "* 'reply_to'\n",
    "* 'retweet_date'\n",
    "* 'translate'\n",
    "* 'trans_src'\n",
    "* 'trans_dest'\n",
    "\n",
    "y values de diferentes tipos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d05795-bd04-427e-b8f4-004b9b52f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "with open('elon_tweets.pickle', 'rb') as handle:\n",
    "    elon_tweets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a798c33a-c2b0-4cb6-b55d-247897f35815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Unnamed: 0': 0,\n",
       "  'id': 15434727182,\n",
       "  'conversation_id': 15434727182,\n",
       "  'created_at': 1275676317000.0,\n",
       "  'date': '2010-06-04 18:31:57',\n",
       "  'timezone': 0,\n",
       "  'place': nan,\n",
       "  'tweet': 'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.',\n",
       "  'language': 'en',\n",
       "  'hashtags': '[]',\n",
       "  'cashtags': '[]',\n",
       "  'user_id': 44196397,\n",
       "  'user_id_str': 44196397,\n",
       "  'username': 'elonmusk',\n",
       "  'name': 'Elon Musk',\n",
       "  'day': 5,\n",
       "  'hour': 18,\n",
       "  'link': 'https://twitter.com/elonmusk/status/15434727182',\n",
       "  'urls': '[]',\n",
       "  'photos': '[]',\n",
       "  'video': 0,\n",
       "  'thumbnail': nan,\n",
       "  'retweet': False,\n",
       "  'nlikes': 4652,\n",
       "  'nreplies': 391,\n",
       "  'nretweets': 348,\n",
       "  'quote_url': nan,\n",
       "  'search': 'None',\n",
       "  'near': nan,\n",
       "  'geo': nan,\n",
       "  'source': nan,\n",
       "  'user_rt_id': nan,\n",
       "  'user_rt': nan,\n",
       "  'retweet_id': nan,\n",
       "  'reply_to': '[]',\n",
       "  'retweet_date': nan,\n",
       "  'translate': nan,\n",
       "  'trans_src': nan,\n",
       "  'trans_dest': nan},\n",
       " {'Unnamed: 0': 0,\n",
       "  'id': 679163784062107649,\n",
       "  'conversation_id': 679163784062107649,\n",
       "  'created_at': 1450760239000.0,\n",
       "  'date': '2015-12-22 04:57:19',\n",
       "  'timezone': 0,\n",
       "  'place': nan,\n",
       "  'tweet': 'High res video of landing from the helo  https://t.co/G0Yq2V5J3m',\n",
       "  'language': 'en',\n",
       "  'hashtags': '[]',\n",
       "  'cashtags': '[]',\n",
       "  'user_id': 44196397,\n",
       "  'user_id_str': 44196397,\n",
       "  'username': 'elonmusk',\n",
       "  'name': 'Elon Musk',\n",
       "  'day': 2,\n",
       "  'hour': 4,\n",
       "  'link': 'https://twitter.com/elonmusk/status/679163784062107649',\n",
       "  'urls': \"['https://m.youtube.com/watch?v=ZCBE8ocOkAQ&feature=youtu.be']\",\n",
       "  'photos': '[]',\n",
       "  'video': 0,\n",
       "  'thumbnail': nan,\n",
       "  'retweet': False,\n",
       "  'nlikes': 9953,\n",
       "  'nreplies': 610,\n",
       "  'nretweets': 6896,\n",
       "  'quote_url': nan,\n",
       "  'search': 'None',\n",
       "  'near': nan,\n",
       "  'geo': nan,\n",
       "  'source': nan,\n",
       "  'user_rt_id': nan,\n",
       "  'user_rt': nan,\n",
       "  'retweet_id': nan,\n",
       "  'reply_to': '[]',\n",
       "  'retweet_date': nan,\n",
       "  'translate': nan,\n",
       "  'trans_src': nan,\n",
       "  'trans_dest': nan},\n",
       " {'Unnamed: 0': 1,\n",
       "  'id': 679145544673923072,\n",
       "  'conversation_id': 679145544673923072,\n",
       "  'created_at': 1450755890000.0,\n",
       "  'date': '2015-12-22 03:44:50',\n",
       "  'timezone': 0,\n",
       "  'place': nan,\n",
       "  'tweet': 'Live video from LZ-1  https://t.co/Ve6gEXfOdh',\n",
       "  'language': 'en',\n",
       "  'hashtags': '[]',\n",
       "  'cashtags': '[]',\n",
       "  'user_id': 44196397,\n",
       "  'user_id_str': 44196397,\n",
       "  'username': 'elonmusk',\n",
       "  'name': 'Elon Musk',\n",
       "  'day': 2,\n",
       "  'hour': 3,\n",
       "  'link': 'https://twitter.com/elonmusk/status/679145544673923072',\n",
       "  'urls': '[]',\n",
       "  'photos': '[]',\n",
       "  'video': 1,\n",
       "  'thumbnail': 'https://pbs.twimg.com/ext_tw_video_thumb/679145419507548161/pu/img/6DQ1zHR6pVDCJdeV.jpg',\n",
       "  'retweet': False,\n",
       "  'nlikes': 10710,\n",
       "  'nreplies': 373,\n",
       "  'nretweets': 5027,\n",
       "  'quote_url': nan,\n",
       "  'search': 'None',\n",
       "  'near': nan,\n",
       "  'geo': nan,\n",
       "  'source': nan,\n",
       "  'user_rt_id': nan,\n",
       "  'user_rt': nan,\n",
       "  'retweet_id': nan,\n",
       "  'reply_to': '[]',\n",
       "  'retweet_date': nan,\n",
       "  'translate': nan,\n",
       "  'trans_src': nan,\n",
       "  'trans_dest': nan}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_tweets[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd775d37-d9b6-457f-acf3-6cf561dbc27f",
   "metadata": {},
   "source": [
    "Responder los siguientes interrogantes de interÃ©s, para lo que se requiere:\n",
    "\n",
    "* Inspeccionar los datos\n",
    "* Formatearlos adecuadamente\n",
    "* Elegir y confeccionar nuevas estructuras de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7c9580-c873-4e53-aa64-5515982f9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2000': [0, 0, 0, '', '', ''], '2001': [0, 0, 0, '', '', ''], '2002': [0, 0, 0, '', '', ''], '2003': [0, 0, 0, '', '', ''], '2004': [0, 0, 0, '', '', ''], '2005': [0, 0, 0, '', '', ''], '2006': [0, 0, 0, '', '', ''], '2007': [0, 0, 0, '', '', ''], '2008': [0, 0, 0, '', '', ''], '2009': [0, 0, 0, '', '', ''], '2010': [0, 0, 0, '', '', ''], '2011': [0, 0, 0, '', '', ''], '2012': [0, 0, 0, '', '', ''], '2013': [0, 0, 0, '', '', ''], '2014': [0, 0, 0, '', '', ''], '2015': [0, 0, 0, '', '', ''], '2016': [0, 0, 0, '', '', ''], '2017': [0, 0, 0, '', '', ''], '2018': [0, 0, 0, '', '', ''], '2019': [0, 0, 0, '', '', ''], '2020': [0, 0, 0, '', '', ''], '2021': [0, 0, 0, '', '', ''], '2022': [0, 0, 0, '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "dict_elon_tweets = {}\n",
    "\n",
    "for k in range(2000,2023):  # k es igual al rango de aÃ±os de los tweets\n",
    "    k = str(k) \n",
    "    dict_elon_tweets[k] = [0,0,0,'','','']  # es una lista vacia donde irÃ¡n los 3 tweets pas popolares \n",
    "    \n",
    "print(dict_elon_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b001ce-12b7-4b6a-b5e0-f067307d5c3a",
   "metadata": {
    "id": "65b001ce-12b7-4b6a-b5e0-f067307d5c3a"
   },
   "source": [
    "**1)** Â¿CuÃ¡les son los tweets (3) mÃ¡s populares *por aÃ±o*? *(mayor cantidad de likes y retweets)*\n",
    "> Deben ser tweets y no retweets o respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c2ec33-f4c4-45e7-87ea-bf6e1f699973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Para cada aÃ±o estos son los tres tweet con mayor popularidad {'2000': [0, 0, 0, '', '', ''], '2001': [0, 0, 0, '', '', ''], '2002': [0, 0, 0, '', '', ''], '2003': [0, 0, 0, '', '', ''], '2004': [0, 0, 0, '', '', ''], '2005': [0, 0, 0, '', '', ''], '2006': [0, 0, 0, '', '', ''], '2007': [0, 0, 0, '', '', ''], '2008': [0, 0, 0, '', '', ''], '2009': [0, 0, 0, '', '', ''], '2010': [5000, 0, 0, 'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.', '', ''], '2011': [214387, 125469, 1614, \"Sew one button, doesn't make u a tailor; cook one meal, doesn't make u a chef; but f* one horse and u r a horsef*er for all of history...\", 'Kanye stopped by the SpaceX rocket factory today.  http://t.co/6z7gHBn6', 'Got called randomly by Kanye West today and received a download of his thoughts, ranging from shoes to Moses. He was polite, but opaque.'], '2012': [35239, 17765, 7460, 'Goal for Model S is to show that electric is way way better than gas. Combine w solar power &amp; the future looks bright.', 'Rough cut simulation of the SpaceX next gen rocket & spaceship design  http://t.co/cKBviQne', \"@DJjodes Would love to make a Tesla supertruck with crazy torque, dynamic air suspension and corners like its on rails. That'd be sweet...\"], '2013': [7880, 5598, 5345, 'Hyperloop Alpha at  http://t.co/ZRTcT2b8bP and  http://t.co/7cucKKprPB  http://t.co/LYhuRxUntA', 'Why does a Tesla fire w no injury get more media headlines than 100,000 gas car fires that kill 100s of people per year?', 'Forgot to say one thing at Tesla annual shareholders meeting: just as my money was the first in, it will be the last out.'], '2014': [22452, 10131, 9399, 'About time to unveil the D and something else  http://t.co/qp23yi59i6', 'Regarding Tesla patents  http://t.co/gGBWoInh6C', 'Noodles in Shinjuku  http://t.co/MWztTqByuA'], '2015': [62839, 26018, 25681, 'There and back again  https://t.co/Ll7wg2hL1G', '11 satellites deployed to target orbit and Falcon has landed back at Cape Canaveral. Headed to LZ-1. Welcome back, baby!', \"The rumor that I'm building a spaceship to get back to my home planet Mars is totally untrue\"], '2016': [50374, 45125, 44086, 'Traffic is driving me nuts. Am going to build a tunnel boring machine and just start digging...', 'Just heard that Norway will ban new sales of fuel cars in 2025. What an amazingly awesome country. You guys rock!!  https://t.co/uAXuBkDYuR', 'Forming a rocket nozzle  https://t.co/QrpcVyHAXr'], '2017': [691687, 521141, 368523, 'Am departing presidential councils. Climate change is real. Leaving Paris is not good for America or the world.', '0 to 100 km/h in 1.9 sec  https://t.co/xTOTDGuwQj', 'Nuclear alien UFO from North Korea  https://t.co/GUIHpKkkp5'], '2018': [1566588, 589093, 550725, 'Had to been done ur welcome  https://t.co/7jT0f9lqIS', 'View from SpaceX Launch Control. Apparently, there is a car in orbit around Earth.  https://t.co/QljN2VnL1O', 'iğŸ–¤anime'], '2019': [910374, 865557, 846785, 'If life is a video game, the graphics are great, but the plot is confusing &amp; the tutorial is way too long', 'And I am forever grateful  https://t.co/kU1pT8t0yv', 'Baby Yoda ğŸ’•  https://t.co/jpQvCccHb9'], '2020': [1899286, 986574, 888177, 'The coronavirus panic is dumb', ' https://t.co/e9dPKVSjjl', '5 mins to T-0'], '2021': [1159144, 1001812, 993661, 'ur welcome  https://t.co/e2KF57KLxb', 'My 14-year-old son, Saxon, said he feels like 2021 will be a good year. I agree. Let us all make it so.', 'Legalize comedy'], '2022': [0, 0, 0, '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3): # una lista para agg los 3 mas populares\n",
    "    for dict_elon in elon_tweets:\n",
    "        is_retweet = dict_elon['retweet']\n",
    "        is_reply = dict_elon['reply_to']\n",
    "        if not is_retweet and is_reply:\n",
    "            years = dict_elon['date'][0:4] # aÃ±o de los tweet\n",
    "            likes = int(dict_elon['nlikes'])  # nÂ° de likes \n",
    "            retweet = int(dict_elon['nretweets']) # nÂ° de retweet\n",
    "            tweet = dict_elon['tweet'] # se trae los string de los tweet\n",
    "            sum_likes_retweet = likes + retweet  \n",
    "            value = dict_elon_tweets[years][i]\n",
    "            if sum_likes_retweet > value and tweet not in dict_elon_tweets[years]:\n",
    "                dict_elon_tweets[years][i] = sum_likes_retweet\n",
    "                dict_elon_tweets[years][i+3] = tweet \n",
    "                \n",
    "print(f' Para cada aÃ±o estos son los tres tweet con mayor popularidad {dict_elon_tweets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111cd58e-7c14-437c-9a58-d269504d3dc6",
   "metadata": {
    "id": "111cd58e-7c14-437c-9a58-d269504d3dc6"
   },
   "source": [
    "**2)** Â¿CuÃ¡les son las palabras mÃ¡s frecuentes en esos tweets? Â¿Se puede inferir alguna conclusiÃ³n sobre *los sentimientos* de dichos tweets?\n",
    "> Obviar las *stop_words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef35c63-34ac-4113-b85b-98f218116560",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop_words = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', \n",
    "                 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \n",
    "                 \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", \n",
    "                 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \n",
    "                 \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', \n",
    "                 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', \n",
    "                 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', \n",
    "                 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', \n",
    "                 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', \n",
    "                 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', \n",
    "                 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b7233c-3be7-4aa2-95be-fd814c0790f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La palabras mas frecuente de los tres tweets de cada aÃ±o entre ellos son ['one', 'make', 'Tesla'] \n"
     ]
    }
   ],
   "source": [
    "list_values  = list(dict_elon_tweets.values())\n",
    "# print(list_values)\n",
    "\n",
    "list_strings = [] \n",
    "\n",
    "for iteration_tweets in list_values:\n",
    "    str_tweets = iteration_tweets[3]\n",
    "    list_strings.append(str_tweets)\n",
    "    str_tweets = iteration_tweets[4]\n",
    "    list_strings.append(str_tweets)\n",
    "    str_tweets = iteration_tweets[5]\n",
    "    list_strings.append(str_tweets)\n",
    "    \n",
    "# print(list_strings)\n",
    "\n",
    "list_strings = ''.join(list_strings)\n",
    "list_strings = list_strings.split(' ')\n",
    "\n",
    "\n",
    "freqs = {}\n",
    "for words in list_strings:\n",
    "    count = freqs.get(words,0)\n",
    "    if words not in en_stop_words and words:\n",
    "        freqs[words] = count + 1 \n",
    "        \n",
    "# print(freqs)\n",
    "\n",
    "list_values = list(freqs.values())\n",
    "max_value = max(list_values)\n",
    "list_of_keys = freqs.keys()\n",
    "key_max = []\n",
    "for keys in list_of_keys: \n",
    "    if freqs[keys] == max_value:\n",
    "        key_max += [keys]\n",
    "    \n",
    "        \n",
    "print(f' La palabras mas frecuente de los tres tweets de cada aÃ±o entre ellos son {key_max} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eaeae9-19b6-4512-ba98-94f79613d3a5",
   "metadata": {
    "id": "f3eaeae9-19b6-4512-ba98-94f79613d3a5"
   },
   "source": [
    "**3)** Â¿CuÃ¡les son las fechas en las que se publicaron los tweets mÃ¡s populares? Â¿Se puede inferir alguna correlaciÃ³n con la fecha (y/u hora) y su popularidad? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b3503e-5b53-4aa4-909f-19d5bcfac6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2000': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2001': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2002': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2003': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2004': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2005': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2006': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2007': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2008': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2009': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2010': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2011': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2012': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2013': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2014': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2015': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2016': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2017': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2018': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2019': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2020': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2021': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2022': [0, 0, 0, '', '', '', '', '', '', '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "dict_elon_tweets = {}\n",
    "\n",
    "for k in range(2000,2023):  # k es igual al rango de aÃ±os de los tweets\n",
    "    k = str(k) \n",
    "    dict_elon_tweets[k] = [0,0,0,'','','','','','','','','']  # es una lista vacia donde irÃ¡n los 3 tweets pas popolares \n",
    "    \n",
    "print(dict_elon_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6294a3f2-e381-479a-94a3-703282d429eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Para cada aÃ±o estas son las fechas de los tweets mÃ¡s populares {'2000': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2001': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2002': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2003': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2004': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2005': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2006': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2007': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2008': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2009': [0, 0, 0, '', '', '', '', '', '', '', '', ''], '2010': [5000, 0, 0, 'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.', '', '', '06-04', '', '', 18, '', ''], '2011': [214387, 125469, 1614, \"Sew one button, doesn't make u a tailor; cook one meal, doesn't make u a chef; but f* one horse and u r a horsef*er for all of history...\", 'Kanye stopped by the SpaceX rocket factory today.  http://t.co/6z7gHBn6', 'Got called randomly by Kanye West today and received a download of his thoughts, ranging from shoes to Moses. He was polite, but opaque.', '12-30', '12-24', '12-21', 3, 1, 11], '2012': [35239, 17765, 7460, 'Goal for Model S is to show that electric is way way better than gas. Combine w solar power &amp; the future looks bright.', 'Rough cut simulation of the SpaceX next gen rocket & spaceship design  http://t.co/cKBviQne', \"@DJjodes Would love to make a Tesla supertruck with crazy torque, dynamic air suspension and corners like its on rails. That'd be sweet...\", '07-31', '01-24', '08-01', 21, 4, 2], '2013': [7880, 5598, 5345, 'Hyperloop Alpha at  http://t.co/ZRTcT2b8bP and  http://t.co/7cucKKprPB  http://t.co/LYhuRxUntA', 'Why does a Tesla fire w no injury get more media headlines than 100,000 gas car fires that kill 100s of people per year?', 'Forgot to say one thing at Tesla annual shareholders meeting: just as my money was the first in, it will be the last out.', '08-12', '11-19', '06-05', 20, 14, 2], '2014': [22452, 10131, 9399, 'About time to unveil the D and something else  http://t.co/qp23yi59i6', 'Regarding Tesla patents  http://t.co/gGBWoInh6C', 'Noodles in Shinjuku  http://t.co/MWztTqByuA', '10-02', '06-12', '09-07', 1, 17, 14], '2015': [62839, 26018, 25681, 'There and back again  https://t.co/Ll7wg2hL1G', '11 satellites deployed to target orbit and Falcon has landed back at Cape Canaveral. Headed to LZ-1. Welcome back, baby!', \"The rumor that I'm building a spaceship to get back to my home planet Mars is totally untrue\", '12-22', '12-22', '03-12', 3, 2, 22], '2016': [50374, 45125, 44086, 'Traffic is driving me nuts. Am going to build a tunnel boring machine and just start digging...', 'Just heard that Norway will ban new sales of fuel cars in 2025. What an amazingly awesome country. You guys rock!!  https://t.co/uAXuBkDYuR', 'Forming a rocket nozzle  https://t.co/QrpcVyHAXr', '12-17', '06-03', '12-09', 13, 18, 22], '2017': [691687, 521141, 368523, 'Am departing presidential councils. Climate change is real. Leaving Paris is not good for America or the world.', '0 to 100 km/h in 1.9 sec  https://t.co/xTOTDGuwQj', 'Nuclear alien UFO from North Korea  https://t.co/GUIHpKkkp5', '06-01', '11-17', '12-23', 20, 6, 2], '2018': [1566588, 589093, 550725, 'Had to been done ur welcome  https://t.co/7jT0f9lqIS', 'View from SpaceX Launch Control. Apparently, there is a car in orbit around Earth.  https://t.co/QljN2VnL1O', 'iğŸ–¤anime', '10-19', '02-06', '10-22', 21, 21, 22], '2019': [910374, 865557, 846785, 'If life is a video game, the graphics are great, but the plot is confusing &amp; the tutorial is way too long', 'And I am forever grateful  https://t.co/kU1pT8t0yv', 'Baby Yoda ğŸ’•  https://t.co/jpQvCccHb9', '12-12', '05-17', '12-13', 7, 6, 9], '2020': [1899286, 986574, 888177, 'The coronavirus panic is dumb', ' https://t.co/e9dPKVSjjl', '5 mins to T-0', '03-06', '06-26', '05-30', 20, 6, 19], '2021': [1159144, 1001812, 993661, 'ur welcome  https://t.co/e2KF57KLxb', 'My 14-year-old son, Saxon, said he feels like 2021 will be a good year. I agree. Let us all make it so.', 'Legalize comedy', '02-04', '01-09', '01-13', 7, 18, 9], '2022': [0, 0, 0, '', '', '', '', '', '', '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3): # una lista para agg los 3 mas populares\n",
    "    for dict_elon in elon_tweets:\n",
    "        is_retweet = dict_elon['retweet']\n",
    "        is_reply = dict_elon['reply_to']\n",
    "        if not is_retweet and is_reply:\n",
    "            years = dict_elon ['date'][0:4] # aÃ±o de los tweet\n",
    "            date = dict_elon ['date'][5:10] #fecha completa de los tweet\n",
    "            hour = dict_elon ['hour'] # hora de los tweets\n",
    "            likes = int(dict_elon['nlikes'])  # nÂ° de likes \n",
    "            retweet = int(dict_elon['nretweets']) # nÂ° de retweet\n",
    "            tweet = dict_elon['tweet'] # se trae los string de los tweet\n",
    "            sum_likes_retweet = likes + retweet  \n",
    "            value = dict_elon_tweets[years][i]\n",
    "            if sum_likes_retweet > value and tweet not in dict_elon_tweets[years]:\n",
    "                dict_elon_tweets[years][i] = sum_likes_retweet\n",
    "                dict_elon_tweets[years][i+3] = tweet \n",
    "                dict_elon_tweets[years][i+6] = date \n",
    "                dict_elon_tweets[years][i+9] = hour\n",
    "                \n",
    "              \n",
    "                \n",
    "print(f' Para cada aÃ±o estas son las fechas de los tweets mÃ¡s populares {dict_elon_tweets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123911e-0328-4600-9a7f-0753e79bbd6d",
   "metadata": {
    "id": "a123911e-0328-4600-9a7f-0753e79bbd6d"
   },
   "source": [
    "**4)** Â¿CuÃ¡les son las personas (3) con las que mÃ¡s interactÃºa Elon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3d9ba8-bdf0-4452-80e4-812d912cd54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estas son las tres personas ['Erdayastronaut', 'flcnhvy', 'PPathole'] con la que Elon Most mÃ¡s interactua\n"
     ]
    }
   ],
   "source": [
    "reply_to_list = []\n",
    "\n",
    "the_three_interacted = []\n",
    "\n",
    "for i in range (len(elon_tweets)):\n",
    "    try:\n",
    "        k = elon_tweets[i]['reply_to'].replace(\",\",\"\").replace(\"'\",\"\").split()[1]\n",
    "        reply_to_list.append(k)\n",
    "    except IndexError:\n",
    "        continue \n",
    "        \n",
    "most_interacted = max(set(reply_to_list), key = reply_to_list.count) \n",
    "the_three_interacted.append(most_interacted) # se agg la 1Â° persona con la que mas interactua \n",
    "# print(most_interacted) # se obtiene el nombre de la persona con la que Elon mas interactua\n",
    "\n",
    "reply_to_list_copy = reply_to_list.copy()\n",
    "second = (\" \".join(reply_to_list_copy)).replace(\"Erdayastronaut\",\"\").split() # se elimina la mayor interacciÃ³n\n",
    "second_interacted = max(set(second), key = second.count) # se obtiene la 2Â° persona con la que mas interactua\n",
    "the_three_interacted.append(second_interacted) # agg el 2Â° con mayor interacciÃ³n\n",
    "\n",
    "\n",
    "reply_to_list_copy1 = reply_to_list.copy()\n",
    "third = (\" \".join(reply_to_list_copy1)).replace(\"Erdayastronaut\",\"\").replace(\"flcnhvy\",\"\").split() # se elimina 1 y 2 mayores\n",
    "third_interacted = max(set(third), key = third.count) # se obtiene la tercera \n",
    "the_three_interacted.append(third_interacted) # agg el 3Â° mayor interaccion \n",
    "\n",
    "\n",
    "print(f' Estas son las tres personas {the_three_interacted} con la que Elon Most mÃ¡s interactua')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff085be-3d8e-455b-a66b-c7e905f4c584",
   "metadata": {
    "id": "7ff085be-3d8e-455b-a66b-c7e905f4c584"
   },
   "source": [
    "**5)** Â¿CuÃ¡les son los tweets mÃ¡s populares con contenido multimedia? (Foto o video) Â¿Se puede inferir algo sobre *por quÃ©* son los mÃ¡s populares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd994fb-ea3f-44e1-9b92-d2a76234d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2010': [0, 0, 0, '', '', ''], '2011': [0, 0, 0, '', '', ''], '2012': [0, 0, 0, '', '', ''], '2013': [0, 0, 0, '', '', ''], '2014': [0, 0, 0, '', '', ''], '2015': [0, 0, 0, '', '', ''], '2016': [0, 0, 0, '', '', ''], '2017': [0, 0, 0, '', '', ''], '2018': [0, 0, 0, '', '', ''], '2019': [0, 0, 0, '', '', ''], '2020': [0, 0, 0, '', '', ''], '2021': [0, 0, 0, '', '', ''], '2022': [0, 0, 0, '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "dict_tweets_photos = {}\n",
    "for k in range(2010,2023):  # k es igual al rango de aÃ±os de los tweets\n",
    "    k = str(k) \n",
    "    dict_tweets_photos[k] = [0,0,0,'','','']  # es una lista vacia donde irÃ¡n los tweets mas populares \n",
    "    \n",
    "print(dict_tweets_photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c41569-5292-4fe6-b76a-1f2943377a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estos son los tweets con contenido de fotos o videos mas poupulares {'2010': [5000, 0, 0, 'Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.', '', ''], '2011': [214387, 125469, 1614, \"Sew one button, doesn't make u a tailor; cook one meal, doesn't make u a chef; but f* one horse and u r a horsef*er for all of history...\", 'Kanye stopped by the SpaceX rocket factory today.  http://t.co/6z7gHBn6', 'Got called randomly by Kanye West today and received a download of his thoughts, ranging from shoes to Moses. He was polite, but opaque.'], '2012': [35239, 17765, 7460, 'Goal for Model S is to show that electric is way way better than gas. Combine w solar power &amp; the future looks bright.', 'Rough cut simulation of the SpaceX next gen rocket & spaceship design  http://t.co/cKBviQne', \"@DJjodes Would love to make a Tesla supertruck with crazy torque, dynamic air suspension and corners like its on rails. That'd be sweet...\"], '2013': [7880, 5598, 5345, 'Hyperloop Alpha at  http://t.co/ZRTcT2b8bP and  http://t.co/7cucKKprPB  http://t.co/LYhuRxUntA', 'Why does a Tesla fire w no injury get more media headlines than 100,000 gas car fires that kill 100s of people per year?', 'Forgot to say one thing at Tesla annual shareholders meeting: just as my money was the first in, it will be the last out.'], '2014': [22452, 10131, 9399, 'About time to unveil the D and something else  http://t.co/qp23yi59i6', 'Regarding Tesla patents  http://t.co/gGBWoInh6C', 'Noodles in Shinjuku  http://t.co/MWztTqByuA'], '2015': [62839, 26018, 25681, 'There and back again  https://t.co/Ll7wg2hL1G', '11 satellites deployed to target orbit and Falcon has landed back at Cape Canaveral. Headed to LZ-1. Welcome back, baby!', \"The rumor that I'm building a spaceship to get back to my home planet Mars is totally untrue\"], '2016': [50374, 45125, 44086, 'Traffic is driving me nuts. Am going to build a tunnel boring machine and just start digging...', 'Just heard that Norway will ban new sales of fuel cars in 2025. What an amazingly awesome country. You guys rock!!  https://t.co/uAXuBkDYuR', 'Forming a rocket nozzle  https://t.co/QrpcVyHAXr'], '2017': [691687, 521141, 368523, 'Am departing presidential councils. Climate change is real. Leaving Paris is not good for America or the world.', '0 to 100 km/h in 1.9 sec  https://t.co/xTOTDGuwQj', 'Nuclear alien UFO from North Korea  https://t.co/GUIHpKkkp5'], '2018': [1566588, 589093, 550725, 'Had to been done ur welcome  https://t.co/7jT0f9lqIS', 'View from SpaceX Launch Control. Apparently, there is a car in orbit around Earth.  https://t.co/QljN2VnL1O', 'iğŸ–¤anime'], '2019': [910374, 865557, 846785, 'If life is a video game, the graphics are great, but the plot is confusing &amp; the tutorial is way too long', 'And I am forever grateful  https://t.co/kU1pT8t0yv', 'Baby Yoda ğŸ’•  https://t.co/jpQvCccHb9'], '2020': [1899286, 986574, 888177, 'The coronavirus panic is dumb', ' https://t.co/e9dPKVSjjl', '5 mins to T-0'], '2021': [1159144, 1001812, 993661, 'ur welcome  https://t.co/e2KF57KLxb', 'My 14-year-old son, Saxon, said he feels like 2021 will be a good year. I agree. Let us all make it so.', 'Legalize comedy'], '2022': [0, 0, 0, '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    for dict_i in elon_tweets:\n",
    "        is_retweet = dict_i['retweet']\n",
    "        is_reply = dict_i['reply_to']\n",
    "        photos = dict_i['photos'] # trae la fotos del tweets \n",
    "        videos = dict_i['video'] # trae el video \n",
    "        if photos or videos: # si hay contenido de foto o video se ejecuta lo demÃ¡s \n",
    "            if not is_retweet and is_reply: # que los tweets no sea retweet ni respuesta \n",
    "                likes = int(dict_i['nlikes'])  # nÂ° de likes \n",
    "                retweet = int(dict_i['nretweets']) # nÂ° de retweet\n",
    "                tweet = dict_i['tweet'] # se trae los tweets \n",
    "                sum_likes_retweet = likes + retweet # interacion de tweets y retweet\n",
    "                years = dict_i['date'][0:4] # aÃ±o de los tweets\n",
    "                value = dict_tweets_photos[years][i] \n",
    "            if sum_likes_retweet > value and tweet not in dict_tweets_photos[years]:\n",
    "                dict_tweets_photos[years][i] = sum_likes_retweet \n",
    "                dict_tweets_photos[years][i+3] = tweet\n",
    "                \n",
    "print(f' Estos son los tweets con contenido de fotos o videos mas poupulares {dict_tweets_photos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8016d8-a00d-4bc4-ac5a-db4e197daae8",
   "metadata": {},
   "source": [
    "**6)** Â¿QuÃ© emojis se pueden encontrar en los tweets de Elon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fba2b2-447e-47d4-9aaa-4678af61fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('en_emojis.pickle', 'rb') as handle:\n",
    "    en_emojis = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9023bc6d-4949-4a52-a29b-935b4b52fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea915ecf-a238-4cd1-b312-993c16275e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_en_emojis = []\n",
    "\n",
    "for key in en_emojis.keys():\n",
    "    list_en_emojis.append(key) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1859ac3-a95e-4f0a-96ec-df749b268e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Los emojis que Elon usa en sus tweets son los siguientes {'ğŸ‘‡', 'ğŸ§›\\u200dâ™€ï¸', 'ğŸ§²', 'ğŸ§±', 'ğŸ', 'ğŸ•Š', 'ğŸ‘¾', 'ğŸ˜›', 'ğŸ§\\u200dâ™‚', 'ğŸ˜±', 'ğŸš€', 'ğŸŸ', 'ğŸ’', 'ğŸ§€', 'ğŸ§\\u200dâ™‚ï¸', 'ğŸŒ¸', 'ğŸ‘»', 'â˜ºï¸', 'ğŸ¤–', 'ğŸ¤¡', 'ğŸ™„', 'ğŸ’¨', 'ğŸ’°', 'ğŸ˜®', 'ğŸ§™\\u200dâ™‚ï¸', 'ğŸ§', 'ğŸ£', 'ğŸŒˆ', 'ğŸ™ƒ', 'ğŸª‘', 'ğŸ˜‡', 'ğŸ˜Š', 'ğŸ‘½', 'ğŸ¤¹', 'ğŸŒŒ', 'ğŸ¥‡', 'ğŸŒ¹', 'ğŸ’«', 'ğŸ¦¶', 'ğŸ’µ', 'ğŸ’›', 'ğŸ·', 'ğŸ˜”', 'ğŸ¤˜', 'ğŸ‘©', 'â›º', 'ğŸ©', 'âœ¨', 'ğŸ›¸', 'ğŸ§¡', 'ğŸƒ', 'ğŸ¤£', 'ğŸ‘¨\\u200dğŸš€', 'â™ ï¸', 'âš”ï¸', 'ğŸ´\\u200dâ˜ ï¸', 'ğŸ‘¨\\u200dğŸ”¬', 'ğŸŒƒ', 'ğŸ·', 'â¤', 'ğŸ˜ˆ', 'ğŸ¦„', 'â™ ', 'â™€ï¸', 'ğŸ¤¹ğŸ»', 'â›ª', 'ğŸ¤', 'ğŸ‰', 'ğŸ¦™', 'âœŒï¸', 'ğŸ´', 'â˜ ï¸', 'ğŸ‘©\\u200dğŸš€', 'ğŸ’£', 'ğŸ˜€', 'ğŸŒ', 'ğŸ’™', 'ğŸ˜', 'ğŸ§›', 'ğŸ‡©ğŸ‡ª', 'ğŸ§¦', 'ğŸ¦Œ', 'ğŸ‡¯ğŸ‡µ', 'ğŸ±', 'ğŸ„', 'ğŸ§š\\u200dâ™€', 'ğŸ»', 'ğŸ‡³ğŸ‡±', 'ğŸ“', 'ğŸ‘', 'ğŸ’•', 'ğŸ§™\\u200dâ™‚', 'â¬‡ï¸', 'â˜ƒï¸', 'ğŸ’š', 'â˜º', 'ğŸ”­', 'ğŸ•º', 'â„¢ï¸', 'ğŸ¼', 'ğŸ•', 'ğŸ´\\u200dâ˜ ', 'ğŸ§™', 'ğŸˆ', 'ğŸ»', 'ğŸš˜', 'â¤ï¸', 'ğŸ˜‚', 'â˜€ï¸', 'ğŸ˜¢', 'ğŸ‡³ğŸ‡´', 'â™€', 'ğŸ', 'ğŸ˜', 'ğŸ’–', 'ğŸ˜‰', 'ğŸ˜', 'ğŸ‡¨ğŸ‡¦', 'ğŸ¶', 'ğŸ§š', 'ğŸ¦Š', 'ğŸ¤ ', 'ğŸ', 'ğŸ˜´', 'ğŸ‘€', 'ğŸ§ ', 'ğŸ¥', 'ğŸ…', 'ğŸ§š\\u200dâ™€ï¸', 'ğŸ¤¹ğŸ»\\u200dâ™‚ï¸', 'ğŸ”¥', 'ğŸ˜', 'ğŸ•³', 'ğŸœ', 'â„¢', 'ğŸ˜…', 'ğŸ˜¬', 'ğŸ¤', 'ğŸ›°', 'â˜ƒ', 'â¬‡', 'ğŸ‡®ğŸ‡¸', 'ğŸ', 'ğŸ‡¦ğŸ‡ª', 'ğŸ©', 'ğŸ', 'ğŸ­', 'ğŸ‘¨', 'ğŸ˜˜', 'ğŸœ', 'ğŸ‚', 'ğŸ‡«ğŸ‡®', 'ğŸ„', 'ğŸ‘¸', 'ğŸ’—', 'ğŸ‡§ğŸ‡´', 'ğŸ‡¦ğŸ‡º', 'â™¥', 'âœŒ', 'â™‚', 'ğŸ‡ºğŸ‡¸', 'ğŸ™', 'ğŸ‰', 'ğŸ’¡', 'ğŸ‘¶ğŸ»', 'ğŸ', 'ğŸ˜ƒ', 'ğŸ’', 'â™‚ï¸', 'ğŸŒª', 'ğŸ˜²', 'ğŸ‡', 'ğŸ–¤', 'ğŸ˜‹', 'ğŸ€', 'â˜ ', 'ğŸ¯', 'ğŸ˜œ', 'ğŸ‡¸ğŸ‡®', 'ğŸ§', 'ğŸ‘Ÿ', 'ğŸƒ', 'ğŸ¥³', 'ğŸ§¨', 'ğŸ¤—', 'ğŸ§›\\u200dâ™€', 'ğŸ¤”', 'ğŸ»', 'âš”', 'ğŸ’¦', 'âš¡', 'ğŸš™', 'ğŸ’¯', 'â­', 'ğŸ”¬', 'ğŸ¥°', 'âš¾', 'â™¥ï¸', 'ğŸ®', 'â˜€', 'ğŸ’©', 'ğŸ†', 'ğŸ’„', 'ğŸ‚', 'ğŸš—', 'ğŸ‘Œ', 'ğŸ§', 'ğŸ¥§', 'ğŸ’œ', 'ğŸ', 'ğŸ˜', 'ğŸ‘', 'ğŸ¤', 'ğŸ’˜', 'â›„', 'ğŸ¦†', 'ğŸ¤“', 'ğŸ¤¹ğŸ»\\u200dâ™‚', 'ğŸ¥œ', 'ğŸ‘†', 'ğŸ‡ºğŸ‡¦', 'ğŸ‡®ğŸ‡©', 'ğŸ¶', 'ğŸŒ', 'ğŸ¼', 'ğŸ¿', 'ğŸ‘¶'}\n"
     ]
    }
   ],
   "source": [
    "list_emojis_tweets = [] \n",
    "\n",
    "for dict_elon in elon_tweets:\n",
    "    tweet = dict_elon['tweet'] # se obtiene los tweets \n",
    "    # text_tweets = (\" \").join(tweet).split(\" \")\n",
    "    for emoji in list_en_emojis: # se guarda la lista de emojis en una vaiable auxiliar\n",
    "        if emoji in tweet: # se busca los emojis entre los tweets \n",
    "            list_emojis_tweets.append(emoji) # se agg los emojis de Elon a una lista nueva  \n",
    "        \n",
    "\n",
    "print(f' Los emojis que Elon usa en sus tweets son los siguientes {set(list_emojis_tweets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a3ad79-7389-4e03-aacb-70513df23df6",
   "metadata": {},
   "source": [
    "**7)** Â¿CuÃ¡les son los (3) mÃ¡s usados? Â¿Se pueden inferir *sentimientos* a partir de los emojis mÃ¡s usados?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62e49b-d585-4e18-856d-d2af2b7f277e",
   "metadata": {},
   "source": [
    "Si, durante el anÃ¡lisis de estos datos se encontrÃ³ algo interesante, gracioso o que se quiera destacar, es posible hacerlo en el siguiente espacio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebf6fb0e-3663-4bd3-be08-e48cf871053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emojis_elon = {}\n",
    "for i in range (1,4):\n",
    "    k = i \n",
    "    dict_emojis_elon[k] = [\"\",0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7033338b-f003-4ea7-9f18-86427eec66e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['', 0], 2: ['', 0], 3: ['', 0]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_emojis_elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "25bfa06d-e682-43b0-80a9-3917402124d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuency = {}\n",
    "three_max_emojis = []\n",
    "\n",
    "for emojis_e in list_emojis_tweets:\n",
    "    count = frecuency.get(emojis_e,0)\n",
    "    if emojis_e in emojis_e:\n",
    "        frecuency[emojis_e] = count + 1  \n",
    "\n",
    "\n",
    "    \n",
    "first_emojis = max(frecuency.values())\n",
    "\n",
    "first_emojis_a = frecuency.get(391)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4de276eb-ddfb-4f5b-9bac-60538aa81eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " None\n"
     ]
    }
   ],
   "source": [
    "print(f' {first_emojis_a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bd109ab1-5851-4731-8e85-972db3ba3d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ğŸ”¥': 81,\n",
       " 'ğŸ‘Œ': 26,\n",
       " 'ğŸ’¨': 55,\n",
       " 'ğŸ': 8,\n",
       " 'ğŸ·': 4,\n",
       " 'ğŸ': 7,\n",
       " 'ğŸ': 13,\n",
       " 'â™¥ï¸': 207,\n",
       " 'â™¥': 207,\n",
       " 'ğŸ’„': 2,\n",
       " 'ğŸ¤£': 391,\n",
       " 'ğŸ¤ ': 2,\n",
       " 'ğŸ˜¬': 4,\n",
       " 'ğŸ˜ƒ': 8,\n",
       " 'ğŸ˜': 2,\n",
       " 'ğŸ’¯': 16,\n",
       " 'ğŸ–¤': 99,\n",
       " 'ğŸ’µ': 2,\n",
       " 'ğŸ‘»': 20,\n",
       " 'ğŸ¶': 20,\n",
       " 'ğŸ˜‰': 91,\n",
       " 'ğŸ’«': 46,\n",
       " 'ğŸ˜€': 162,\n",
       " 'ğŸš€': 104,\n",
       " 'ğŸ‘': 57,\n",
       " 'â™ ï¸': 2,\n",
       " 'â™ ': 2,\n",
       " 'ğŸ‡¨ğŸ‡¦': 6,\n",
       " 'ğŸ¤—': 39,\n",
       " 'ğŸ˜´': 10,\n",
       " 'ğŸ‘‡': 2,\n",
       " 'ğŸ’°': 7,\n",
       " 'ğŸ›°': 32,\n",
       " 'ğŸ˜¢': 20,\n",
       " 'ğŸ¤˜': 2,\n",
       " 'ğŸ’©': 21,\n",
       " 'âš¡': 13,\n",
       " 'ğŸ‡©ğŸ‡ª': 7,\n",
       " 'ğŸ“': 2,\n",
       " 'â˜ºï¸': 23,\n",
       " 'â˜º': 23,\n",
       " 'ğŸ‘€': 11,\n",
       " 'ğŸ‘†': 4,\n",
       " 'ğŸ': 2,\n",
       " 'ğŸ˜': 5,\n",
       " 'ğŸ¯': 2,\n",
       " 'ğŸ‡ºğŸ‡¸': 4,\n",
       " 'ğŸ§™': 17,\n",
       " 'â™‚ï¸': 22,\n",
       " 'â™‚': 22,\n",
       " 'ğŸ§™\\u200dâ™‚ï¸': 17,\n",
       " 'ğŸ§™\\u200dâ™‚': 17,\n",
       " 'ğŸ˜': 17,\n",
       " 'â™€ï¸': 16,\n",
       " 'â™€': 16,\n",
       " 'ğŸ§›': 6,\n",
       " 'ğŸ§›\\u200dâ™€ï¸': 6,\n",
       " 'ğŸ§›\\u200dâ™€': 6,\n",
       " 'ğŸ˜®': 6,\n",
       " 'ğŸ’•': 50,\n",
       " 'ğŸ•Š': 2,\n",
       " 'ğŸŒ¹': 8,\n",
       " 'ğŸ‡®ğŸ‡©': 2,\n",
       " 'ğŸ‡§ğŸ‡´': 2,\n",
       " 'ğŸ»': 18,\n",
       " 'ğŸ˜ˆ': 5,\n",
       " 'ğŸ¤”': 35,\n",
       " 'âœ¨': 6,\n",
       " 'ğŸ˜‚': 2,\n",
       " 'ğŸˆ': 11,\n",
       " 'ğŸ˜…': 22,\n",
       " 'â¤ï¸': 36,\n",
       " 'â¤': 36,\n",
       " 'ğŸ': 20,\n",
       " 'ğŸ§š': 10,\n",
       " 'ğŸ‘¸': 2,\n",
       " 'ğŸ§š\\u200dâ™€ï¸': 10,\n",
       " 'ğŸ§š\\u200dâ™€': 10,\n",
       " 'ğŸ§²': 5,\n",
       " 'ğŸ¥œ': 22,\n",
       " 'ğŸ¤“': 2,\n",
       " 'ğŸ‡': 14,\n",
       " 'ğŸ’–': 9,\n",
       " 'âœŒï¸': 17,\n",
       " 'âœŒ': 17,\n",
       " 'ğŸ”­': 4,\n",
       " 'ğŸ˜Š': 10,\n",
       " 'ğŸ’˜': 6,\n",
       " 'ğŸ»': 4,\n",
       " 'ğŸ¤¹ğŸ»\\u200dâ™‚ï¸': 2,\n",
       " 'ğŸ¤¹ğŸ»\\u200dâ™‚': 2,\n",
       " 'ğŸ¤¹': 2,\n",
       " 'ğŸ¤¹ğŸ»': 2,\n",
       " 'ğŸ•º': 2,\n",
       " 'â˜ƒï¸': 2,\n",
       " 'â˜ƒ': 2,\n",
       " 'ğŸª‘': 2,\n",
       " 'ğŸ»': 2,\n",
       " 'ğŸŒ': 13,\n",
       " 'ğŸ˜': 2,\n",
       " 'ğŸ‘¶': 3,\n",
       " 'ğŸ‘¶ğŸ»': 2,\n",
       " 'ğŸš˜': 49,\n",
       " 'â˜€ï¸': 2,\n",
       " 'â˜€': 2,\n",
       " 'ğŸ¥': 5,\n",
       " 'ğŸ§±': 2,\n",
       " 'ğŸŒ': 14,\n",
       " 'ğŸ„': 10,\n",
       " 'ğŸ¼': 3,\n",
       " 'ğŸ¤': 3,\n",
       " 'âš”ï¸': 3,\n",
       " 'âš”': 3,\n",
       " 'ğŸ§': 3,\n",
       " 'ğŸ§\\u200dâ™‚ï¸': 3,\n",
       " 'ğŸ§\\u200dâ™‚': 3,\n",
       " 'ğŸ’›': 14,\n",
       " 'ğŸ˜˜': 7,\n",
       " 'ğŸƒ': 3,\n",
       " 'ğŸ¥‡': 3,\n",
       " 'â„¢ï¸': 9,\n",
       " 'â„¢': 9,\n",
       " 'ğŸŸ': 3,\n",
       " 'ğŸ§ ': 25,\n",
       " 'ğŸ•³': 3,\n",
       " 'ğŸ¤': 3,\n",
       " 'ğŸ¦Œ': 3,\n",
       " 'ğŸ¦¶': 3,\n",
       " 'ğŸ‘': 3,\n",
       " 'ğŸ¥§': 6,\n",
       " 'ğŸ’£': 3,\n",
       " 'ğŸ’¦': 3,\n",
       " 'ğŸ‡®ğŸ‡¸': 6,\n",
       " 'ğŸ‡¸ğŸ‡®': 3,\n",
       " 'ğŸ¥³': 9,\n",
       " 'ğŸ˜²': 9,\n",
       " 'ğŸ‡³ğŸ‡±': 7,\n",
       " 'ğŸ‡³ğŸ‡´': 19,\n",
       " 'ğŸ˜‹': 9,\n",
       " 'ğŸ€': 12,\n",
       " 'ğŸ§': 3,\n",
       " 'ğŸ©': 8,\n",
       " 'ğŸ¤': 3,\n",
       " 'ğŸ': 9,\n",
       " 'ğŸ·': 3,\n",
       " 'ğŸ‘½': 31,\n",
       " 'ğŸ¤–': 10,\n",
       " 'ğŸ¦†': 9,\n",
       " 'ğŸ˜‡': 7,\n",
       " 'ğŸ£': 3,\n",
       " 'ğŸ§¨': 3,\n",
       " 'â¬‡ï¸': 3,\n",
       " 'â¬‡': 3,\n",
       " 'ğŸŒŒ': 7,\n",
       " 'ğŸ´': 3,\n",
       " 'ğŸ´\\u200dâ˜ ï¸': 3,\n",
       " 'ğŸ´\\u200dâ˜ ': 3,\n",
       " 'â˜ ï¸': 3,\n",
       " 'â˜ ': 3,\n",
       " 'ğŸ˜”': 10,\n",
       " 'ğŸ‡«ğŸ‡®': 3,\n",
       " 'ğŸ’™': 10,\n",
       " 'ğŸ­': 7,\n",
       " 'ğŸ™': 11,\n",
       " 'ğŸ˜œ': 13,\n",
       " 'ğŸ‚': 3,\n",
       " 'ğŸƒ': 10,\n",
       " 'ğŸ': 3,\n",
       " 'ğŸ‡¯ğŸ‡µ': 8,\n",
       " 'ğŸ’¡': 10,\n",
       " 'ğŸ§¦': 6,\n",
       " 'ğŸ§€': 3,\n",
       " 'ğŸ§': 3,\n",
       " 'ğŸ¿': 3,\n",
       " 'ğŸ¦Š': 7,\n",
       " 'ğŸœ': 6,\n",
       " 'ğŸ˜': 3,\n",
       " 'ğŸ‘Ÿ': 3,\n",
       " 'ğŸ¤¡': 6,\n",
       " 'ğŸ¼': 7,\n",
       " 'ğŸ¥°': 3,\n",
       " 'ğŸŒª': 3,\n",
       " 'ğŸ‰': 7,\n",
       " 'ğŸ‘¨': 7,\n",
       " 'ğŸ‘¨\\u200dğŸš€': 3,\n",
       " 'ğŸ‘©': 3,\n",
       " 'ğŸ‘©\\u200dğŸš€': 3,\n",
       " 'â­': 3,\n",
       " 'ğŸ‡ºğŸ‡¦': 4,\n",
       " 'ğŸ…': 4,\n",
       " 'ğŸ’': 4,\n",
       " 'â›„': 4,\n",
       " 'ğŸœ': 4,\n",
       " 'âš¾': 4,\n",
       " 'ğŸ¦™': 4,\n",
       " 'ğŸ›¸': 16,\n",
       " 'ğŸ’—': 4,\n",
       " 'ğŸ‘¾': 8,\n",
       " 'ğŸ®': 4,\n",
       " 'ğŸ¶': 4,\n",
       " 'ğŸ˜›': 4,\n",
       " 'ğŸ”¬': 12,\n",
       " 'ğŸ‘¨\\u200dğŸ”¬': 4,\n",
       " 'ğŸ˜±': 4,\n",
       " 'ğŸ¦„': 8,\n",
       " 'ğŸ©': 4,\n",
       " 'ğŸ‚': 4,\n",
       " 'ğŸ‰': 8,\n",
       " 'ğŸ’': 4,\n",
       " 'ğŸ’š': 4,\n",
       " 'ğŸ§¡': 4,\n",
       " 'ğŸ’œ': 4,\n",
       " 'ğŸŒˆ': 4,\n",
       " 'â›º': 4,\n",
       " 'â›ª': 4,\n",
       " 'ğŸŒƒ': 4,\n",
       " 'ğŸ„': 4,\n",
       " 'ğŸ•': 4,\n",
       " 'ğŸ™ƒ': 4,\n",
       " 'ğŸš—': 4,\n",
       " 'ğŸš™': 4,\n",
       " 'ğŸ‡¦ğŸ‡ª': 4,\n",
       " 'ğŸŒ¸': 4,\n",
       " 'ğŸ±': 4,\n",
       " 'ğŸ‡¦ğŸ‡º': 4,\n",
       " 'ğŸ™„': 1,\n",
       " 'ğŸ†': 1}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frecuency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e178e0-0f54-4fee-bdb5-cbe6c87301df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "analisis-de-producto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
